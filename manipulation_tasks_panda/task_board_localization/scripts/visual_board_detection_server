#!/usr/bin/env python3

import rospy
import actionlib
import roslib
import rospkg
import time
import quaternion
import open3d as o3d
import numpy as np
import copy
import ros_numpy
from geometry_msgs.msg import Pose, PoseStamped

from task_board_localization.srv import (
    PointDetect,
    PointDetectRequest,
    PointDetectResponse,
)

debug = True


def draw_registration_result(source, target, transformation):
    """
    visualization for the global registration results
    @param source: source point cloud
    @param target: traget point cloud
    @param transformation: transformation from global registration
    @return: an image showing the results
    """
    if not debug:
        return
    source_temp = copy.deepcopy(source)
    target_temp = copy.deepcopy(target)
    source_temp.paint_uniform_color([1, 0.706, 0])
    target_temp.paint_uniform_color([0, 0.651, 0.929])
    source_temp.transform(transformation)
    o3d.visualization.draw_geometries([source_temp, target_temp])


def preprocess_point_cloud(pcd, voxel_size):
    """
    pre-processing of the point cloud, down-sampling and estimate the normal vectors
    @param pcd: point cloud
    @param voxel_size: a parameter that determines the voxel size for computing the features
    @return: processed point cloud
    """
    print(":: Downsample with a voxel size %.3f." % voxel_size)
    pcd_down = pcd.voxel_down_sample(voxel_size)

    radius_normal = voxel_size  # * 2
    print(":: Estimate normal with search radius %.3f." % radius_normal)
    pcd_down.estimate_normals(
        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=100)
    )
    if debug:
        o3d.visualization.draw_geometries([pcd_down], point_show_normal=True)
    radius_feature = voxel_size  # * 5
    print(":: Compute FPFH feature with search radius %.3f." % radius_feature)
    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(
        pcd_down,
        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100),
    )

    return pcd_down, pcd_fpfh


def prepare_dataset(voxel_size, target, new_source=False):
    """
    read the point cloud data and crop the table plane
    @param voxel_size: voxel size for processing step
    @param target: target point cloud
    @return: raw and processed point clouds
    """
    print(":: Load source point clouds.")
    ros_pack = rospkg.RosPack()
    package_path = ros_pack.get_path("task_board_localization")
    file_name = "reference_box_point_cloud.ply"  # Should be a parameter
    abs_file_name = package_path + "/models/" + file_name

    source = o3d.io.read_point_cloud(abs_file_name)
    model_numpy = ros_numpy.numpify(target)

    xyz = [(x, y, z) for x, y, z, rgb in model_numpy]
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(np.array(xyz))
    draw_registration_result(source, pcd, np.identity(4))

    # processing of the target pointcloud via boundaries
    lb = pcd.get_min_bound()
    ub = pcd.get_max_bound()
    print("lower bounds of the un-processed pointcloud: ", lb)
    print("upper bounds of the un-processed pointcloud: ", ub)

    # cropping both source and target along z-axis
    ub[-1] = rospy.get_param('visual_board_detection/height_threshold')
    min_bound = lb
    max_bound = ub
    box = o3d.geometry.AxisAlignedBoundingBox(min_bound, max_bound)
    target = pcd.crop(box)
    source = source.crop(box)

    # Overwrite the current pointcloud file
    if new_source:
        o3d.io.write_point_cloud(abs_file_name, target)
        pcd_load = o3d.io.read_point_cloud("target.ply")
        trans_init = np.asarray(
            [
                [0.0, 0.0, 1.0, 0.0],
                [1.0, 0.0, 0.0, 0.0],
                [0.0, 1.0, 0.0, 0.0],
                [0.0, 0.0, 0.0, 1.0],
            ]
        )
        source.transform(trans_init)

    draw_registration_result(source, target, np.identity(4))

    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)
    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)

    return source, target, source_down, target_down, source_fpfh, target_fpfh


def execute_global_registration(
    source_down, target_down, source_fpfh, target_fpfh, voxel_size
):
    """
    run RANSAC global registration step
    @param source_down: down-sampled source point cloud
    @param target_down: down-sampled target point cloud
    @param source_fpfh: fpfh feature of the source point cloud
    @param target_fpfh: fpfh feature of the target point cloud
    @param voxel_size: voxel size
    @return: transformation
    """
    distance_threshold = voxel_size * 1.5
    print(":: RANSAC registration on downsampled point clouds.")
    print("   Since the downsampling voxel size is %.3f," % voxel_size)
    print("   we use a liberal distance threshold %.3f." % distance_threshold)
    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(
        source=source_down,
        target=target_down,
        source_feature=source_fpfh,
        target_feature=target_fpfh,
        max_correspondence_distance=distance_threshold,
        estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(
            False
        ),
        ransac_n=4,
        checkers=[
            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),
            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(
                distance_threshold
            ),
        ],
        criteria=o3d.pipelines.registration.RANSACConvergenceCriteria(
            4000000, 0.9999999
        ),
        mutual_filter=False,
    )
    return result


def refine_registration(source, target, voxel_size, result_ransac):
    """
    point-to-plane icp step
    @param source: source point cloud
    @param target: target point cloud
    @param source_fpfh: fpfh feature of the source point cloud
    @param target_fpfh: fpfh feature of the target point cloud
    @param voxel_size: voxel size
    @param result_ransac: result from the global registration
    @return: the refined transformation
    """
    distance_threshold = voxel_size * 0.4
    print(":: Point-to-plane ICP registration is applied on original point")
    print("   clouds to refine the alignment. This time we use a strict")
    print("   distance threshold %.3f." % distance_threshold)
    target.estimate_normals()
    result = o3d.pipelines.registration.registration_icp(
        source,
        target,
        distance_threshold,
        result_ransac.transformation,
        o3d.pipelines.registration.TransformationEstimationPointToPlane(),
    )
    return result


# gives the point cloud of the camera sensor (scene)
def point_detect(req):
    """
    given a request, execute the board visual detection
    @param req: service request
    @return: the transformation
    """
    voxel_size = rospy.get_param('visual_board_detection/voxel_size')  # means 5cm for the dataset
    source, target, source_down, target_down, source_fpfh, target_fpfh = prepare_dataset(
        voxel_size, req.cloud, req.success
    )

    result_ransac = execute_global_registration(
        source_down, target_down, source_fpfh, target_fpfh, voxel_size
    )
    draw_registration_result(source_down, target_down, result_ransac.transformation)
    result_icp = refine_registration(source, target, voxel_size, result_ransac)

    trans = result_icp.transformation
    draw_registration_result(source, target, result_icp.transformation)

    # Store the created homogeneous matrix as a PoseStamped message
    rot_matrix = trans[:3, :3]
    translation = trans[:, 3]

    detected_quat = quaternion.from_rotation_matrix(rot_matrix)
    posestamp = PoseStamped()
    pose = Pose()
    pose.position.x = translation[0]
    pose.position.y = translation[1]
    pose.position.z = translation[2]
    pose.orientation.w = detected_quat.w
    pose.orientation.x = detected_quat.x
    pose.orientation.y = detected_quat.y
    pose.orientation.z = detected_quat.z
    posestamp.pose = pose
    return PointDetectResponse(posestamp)


def point_server():
    """
    running the service
    """
    s = rospy.Service("point_detect", PointDetect, point_detect)


if __name__ == "__main__":
    rospy.init_node("point_server")
    point_server()
    print("point server started")
    rospy.spin()
