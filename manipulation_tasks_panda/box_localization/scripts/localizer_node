#!/usr/bin/env python
import sys
import os
from geometry_msgs.msg import PointStamped
import rospy
from sensor_msgs.msg import Image, PointCloud2 
from robothon23vision.localization.localizer import Localizer
import numpy as np
import ros_numpy

import tf

from cv_bridge import CvBridge, CvBridgeError
import cv2
from cv2 import imshow, waitKey, imwrite, COLOR_BGR2RGB, cvtColor

class SimpleLocalizerNode():
    def __init__(self) -> None:
        rospy.init_node("localizer_node")
        self._rate = rospy.Rate(10)
        self.bridge = CvBridge()
        self.image_publisher = rospy.Publisher("/image_detection", Image, queue_size=10)
        self.image_sub = rospy.Subscriber('/camera/color/image_raw', Image, self.image_callback)
        self.pcl_sub = rospy.Subscriber('/camera/depth/color/points', PointCloud2, self.pcl_callback)
        self.curr_image = None
        self.pcl = None
        self._tf_publisher = tf.TransformBroadcaster()
        self._tf_listener = tf.TransformListener()

    def pcl_callback(self, data):
        converted = ros_numpy.numpify(data)
        self.pcl = ros_numpy.point_cloud2.split_rgb_field(converted)
        

    def image_callback(self, data):
        cv_image = self.bridge.imgmsg_to_cv2(data, "bgr8")
        self.curr_image = cv_image

    def get_transformation_matrix(self) -> np.ndarray:
        while True:
            try:
                rp_tr, rp_rt = self._tf_listener.lookupTransform('panda_link0', 'camera_link', rospy.Time.now())
                break
            except Exception as e:
                rospy.logwarn(e)
        T = np.dot(tf.transformations.translation_matrix(rp_tr), tf.transformations.quaternion_matrix(rp_rt))
        return T


    def publisher_localization(self):
        rospy.init_node("localizer_node")
        if self.curr_image is None or self.pcl is None:
            print("no image")
            return
        localizer = Localizer(self.curr_image)
        localizer.detect_points()
        """
        points = localizer._points
        coordinates_points = {}
        matrix = self.get_transformation_matrix()
        for name, pixels in points.items():
            point_in_camera_frame = np.array(list(self.pcl[pixels[1], pixels[0]])[0:3] + [1])
            coordinates_points[name] = np.dot(matrix, point_in_camera_frame)
        print(coordinates_points)
        tf_matrix = localizer.compute_full_tf_in_m()
        position = tf_matrix[0:3, 3]
        quaternion = tf.transformations.quaternion_from_matrix(tf_matrix[0:4, 0:4])
        quaternion = quaternion/np.linalg.norm(quaternion)
        self._tf_publisher.sendTransform(position,
                                         quaternion,
                                         rospy.Time.now(),
                                         "box_tf",
                                         "panda_link0")

        """
        self.publish_annoted_image(self.curr_image, localizer._points)

    def publish_annoted_image(self, image, points):
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.8
        font_color = (0, 0, 255)
        thickness = 1
        for key, center in points.items():

            cv2.circle(image, center, 10, (0, 0, 255), 2)
            cv2.circle(image, center, 2, (0, 0, 255), 3)
            cv2.putText(image, key, (center[0]+15, center[1]), font, font_scale, font_color, thickness)

        ros_image = self.bridge.cv2_to_imgmsg(image, "bgr8")
        self.image_publisher.publish(ros_image)


    def run(self):
        self._rate.sleep()
        while not rospy.is_shutdown():
            self.publisher_localization()
            self._rate.sleep()
    

if __name__ == '__main__':
    simple_localizer_node = SimpleLocalizerNode()
    try:
        simple_localizer_node.run()
    except rospy.ROSInterruptException:
        pass
