#!/usr/bin/env python3
import sys
import os
from geometry_msgs.msg import PointStamped
from geometry_msgs.msg import Pose, PoseStamped
from std_msgs.msg import Bool
import rospy
from sensor_msgs.msg import Image, PointCloud2 
from robothon23vision.localization.localizer import Localizer
from robothon23vision.localization.localizer_sift import Localizer as LocalizerSift
from robothon23vision.detectors import *
import numpy as np
import ros_numpy
import dynamic_reconfigure.client

import tf

from cv_bridge import CvBridge, CvBridgeError
import cv2
from cv2 import imshow, waitKey, imwrite, COLOR_BGR2RGB, cvtColor

from queue import Queue

def median_of_queue(q):
    n = q.qsize()
    median = np.median(np.array(list(q.queue)), axis=0)
    return median




class SimpleLocalizerNode():
    def __init__(self) -> None:
        rospy.init_node("localizer_node")
        self._rate = rospy.Rate(5)
        #self._localizer = Localizer(debug=False)
        self._localizer = LocalizerSift('template.png')
        self.bridge = CvBridge()
        self.image_publisher = rospy.Publisher("/image_detection", Image, queue_size=10)
        self.image_sub = rospy.Subscriber('/camera/color/image_raw', Image, self.image_callback)
        self.ground_truth_sub = rospy.Subscriber('/set_ground_truth', Bool, self.save_ground_truth_callback)
        self.stop_localizer_sub = rospy.Subscriber('/stop_localization', Bool, self.stop_localization_callback)
        self.pcl_sub = rospy.Subscriber('/camera/depth/color/points', PointCloud2, self.pcl_callback)
        #self._reconfig_client = dynamic_reconfigure.client.Client("filter_server", timeout=None, config_callback=self.parameter_callback)
        self.curr_image = None
        self.pcl = None
        self._tf_publisher = tf.TransformBroadcaster()
        self._tf_listener = tf.TransformListener()
        self._compute_localization = True
        self._pose_publisher = rospy.Publisher("/box_transform_intermediate", PoseStamped, queue_size=1)
        self._tf_matrix = None
        self._publisher_counter = 0
        """
        ground_truth = {
                'red_button': np.array([ 0.44298418, -0.13936999,  0.06562096,  1.        ]),
                'gray_area': np.array([ 0.42750605, -0.01992776,  0.07104067,  1.        ]),
                'blue_area': np.array([ 0.40160332, -0.16709677,  0.07850175,  1.        ]),
                'blue_button': np.array([ 0.46368945, -0.16779211,  0.06750948,  1.        ])
        }
        ground_truth = {
                'red_button': np.array([ 0.44298418, -0.13936999,  0.,  1.        ]),
                'gray_area': np.array([ 0.42750605, -0.01992776,  0.,  1.        ]),
                'blue_area': np.array([ 0.40160332, -0.16709677,  0.,  1.        ]),
                'blue_button': np.array([ 0.46368945, -0.16779211,  0.,  1.        ])
        }
        """
        ground_truth = {
                'red_button': (418, -104),
                'blue_button': (477, -146),
                'gray_area': (187, -90),
                'blue_area': (477, -27),
        }
        self._window = Queue(maxsize=30)

        #self._localizer.set_ground_truth(ground_truth)

    def parameter_callback(self, data):
        self._config = data
        print(self._config)

    def stop_localization_callback(self, data):
        self._compute_localization = False

    def save_ground_truth_callback(self, data):
        #print(self.coordinates_points)
        #print(self._localizer._points)
        for key, item in self._localizer._points.items():
            print(key)
            print(item[0] - 640)
            print(item[1] - 360)
        #self._localizer.set_ground_truth(self.coordinates_points)


    def pcl_callback(self, data):
        converted = ros_numpy.numpify(data)
        self.pcl = ros_numpy.point_cloud2.split_rgb_field(converted)
        

    def image_callback(self, data):
        cv_image = self.bridge.imgmsg_to_cv2(data, "bgr8")
        self.curr_image = cv_image

    def get_transformation_matrix(self) -> np.ndarray:
        while True:
            try:
                rp_tr, rp_rt = self._tf_listener.lookupTransform('panda_link0', 'camera_color_optical_frame', rospy.Time.now() - rospy.Duration(1))
                break
            except Exception as e:
                rospy.logwarn(e)
        T = np.dot(tf.transformations.translation_matrix(rp_tr), tf.transformations.quaternion_matrix(rp_rt))
        return T

    def get_config_detector(self, detector_name: str) -> dict:
        config_detector = {}
        for i in ['h', 's', 'v']:
            config_detector[f'{i}_low'] = self._config[f'{detector_name}_{i}_low']
            config_detector[f'{i}_high'] = self._config[f'{detector_name}_{i}_up']
        return config_detector

    def compute_localization_in_pixels(self):
        if self.curr_image is None or self.pcl is None:
            rospy.logwarn("no image")
            return

        self._localizer.set_image(self.curr_image)

        self._localizer.detect_points()
        #points = self._localizer._points
        tf_matrix = self._localizer.compute_full_tf_in_m()
        self._window.put(tf_matrix)
        if self._window.full():
            # Process items in the window
            self._window.get()
            self._tf_matrix = median_of_queue(self._window)
        #print(self._tf_matrix)
        self._publisher_counter += 1
        if self._publisher_counter % 10 == 0:
            self.publish_annoted_image(self._localizer.annoted_image(), {})


    def compute_localization(self):
        if self.curr_image is None or self.pcl is None:
            rospy.logwarn("no image")
            return

        self._localizer.set_image(self.curr_image)

        self._localizer.detect_points()
        points = self._localizer._points
        self.coordinates_points = {}
        matrix = self.get_transformation_matrix()
        for name, pixels in points.items():
            try:
                point_in_camera_frame = np.array(list(self.pcl[pixels[1], pixels[0]])[0:3] + [1])
                self.coordinates_points[name] = np.dot(matrix, point_in_camera_frame)
                self.coordinates_points[name][2] = 0
            except Exception as e:
                rospy.logwarn(e)
        self._localizer.set_coordinate_locations(self.coordinates_points)
        tf_matrix = self._localizer.compute_coordinate_tf()
        self._window.put(tf_matrix)
        if self._window.full():
            # Process items in the window
            self._window.get()
            self._tf_matrix = median_of_queue(self._window)
        self.publish_annoted_image(self.curr_image, self._localizer._points)


    def publish_localization(self) -> None:
        if self._tf_matrix is None:
            return
        position = self._tf_matrix[0:3, 3]
        quaternion = tf.transformations.quaternion_from_matrix(self._tf_matrix[0:4, 0:4])
        quaternion = quaternion/np.linalg.norm(quaternion)
        # Publish pose
        pose = PoseStamped()
        pose.pose.position.x = position[0]
        pose.pose.position.y = position[1]
        pose.pose.position.z = position[2]
        pose.pose.orientation.w = quaternion[3]
        pose.pose.orientation.x = quaternion[0]
        pose.pose.orientation.y = quaternion[1]
        pose.pose.orientation.z = quaternion[2]
        self._pose_publisher.publish(pose)
        # Publish tf
        self._tf_publisher.sendTransform(position,
                                         quaternion,
                                         rospy.Time.now(),
                                         "box_tf",
                                         "panda_link0")

    def publish_annoted_image(self, image, points):
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.8
        font_color = (0, 0, 255)
        thickness = 1
        for key, center in points.items():

            cv2.circle(image, center, 10, (0, 0, 255), 2)
            cv2.circle(image, center, 2, (0, 0, 255), 3)
            cv2.putText(image, key, (center[0]+15, center[1]), font, font_scale, font_color, thickness)

        #print(type(self._localizer._detectors[1]))
        #ros_image = self.bridge.cv2_to_imgmsg(self._localizer._detectors[1].filtered_img(), "bgr8")
        ros_image = self.bridge.cv2_to_imgmsg(image, "bgr8")
        self.image_publisher.publish(ros_image)


    def run(self):
        self._rate.sleep()
        while not rospy.is_shutdown():
            if self._compute_localization:
                self.compute_localization_in_pixels()
            self.publish_localization()
            self._rate.sleep()
    

if __name__ == '__main__':
    simple_localizer_node = SimpleLocalizerNode()
    try:
        simple_localizer_node.run()
    except rospy.ROSInterruptException:
        pass
