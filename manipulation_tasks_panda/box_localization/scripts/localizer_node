#!/usr/bin/env python3
import sys
import os
from geometry_msgs.msg import PointStamped
from geometry_msgs.msg import Pose
import rospy
from sensor_msgs.msg import Image, PointCloud2 
from robothon23vision.localization.localizer import Localizer
import numpy as np
import ros_numpy

import tf

from cv_bridge import CvBridge, CvBridgeError
import cv2
from cv2 import imshow, waitKey, imwrite, COLOR_BGR2RGB, cvtColor

class SimpleLocalizerNode():
    def __init__(self) -> None:
        rospy.init_node("localizer_node")
        self._rate = rospy.Rate(10)
        self._localizer = Localizer(debug=False)
        self.bridge = CvBridge()
        self.image_publisher = rospy.Publisher("/image_detection", Image, queue_size=10)
        self.image_sub = rospy.Subscriber('/camera/color/image_raw', Image, self.image_callback)
        self.pcl_sub = rospy.Subscriber('/camera/depth/color/points', PointCloud2, self.pcl_callback)
        self.curr_image = None
        self.pcl = None
        self._tf_publisher = tf.TransformBroadcaster()
        self._tf_listener = tf.TransformListener()
        self._pose_publisher = rospy.Publisher("/box_transform", Pose, queue_size=10)
        ground_truth = {
                'red_button': np.array([ 0.42972328, -0.16320301,  0.06627839,  1.        ]),
                'gray_area': np.array([ 0.42006164, -0.01094113,  0.0655315 ,  1.        ]),
                'blue_area': np.array([ 0.38310724, -0.15873512,  0.07945754,  1.        ]),
                'blue_button': np.array([ 0.37664535, -0.160712  ,  0.07844406,  1.        ])
                }
        self._localizer.set_ground_truth(ground_truth)


    def pcl_callback(self, data):
        converted = ros_numpy.numpify(data)
        self.pcl = ros_numpy.point_cloud2.split_rgb_field(converted)
        

    def image_callback(self, data):
        cv_image = self.bridge.imgmsg_to_cv2(data, "bgr8")
        self.curr_image = cv_image

    def get_transformation_matrix(self) -> np.ndarray:
        while True:
            try:
                rp_tr, rp_rt = self._tf_listener.lookupTransform('panda_link0', 'camera_color_optical_frame', rospy.Time.now() - rospy.Duration(1))
                break
            except Exception as e:
                rospy.logwarn(e)
        T = np.dot(tf.transformations.translation_matrix(rp_tr), tf.transformations.quaternion_matrix(rp_rt))
        return T


    def publisher_localization(self):
        rospy.init_node("localizer_node")
        if self.curr_image is None or self.pcl is None:
            rospy.logwarn("no image")
            return

        self._localizer.set_image(self.curr_image)
        self._localizer.detect_points()
        points = self._localizer._points
        coordinates_points = {}
        matrix = self.get_transformation_matrix()
        for name, pixels in points.items():
            try:
                point_in_camera_frame = np.array(list(self.pcl[pixels[1], pixels[0]])[0:3] + [1])
                coordinates_points[name] = np.dot(matrix, point_in_camera_frame)
            except Exception as e:
                rospy.logwarn(e)
        self._localizer.set_coordinate_locations(coordinates_points)
        tf_matrix = self._localizer.compute_coordinate_tf()
        position = tf_matrix[0:3, 3]
        quaternion = tf.transformations.quaternion_from_matrix(tf_matrix[0:4, 0:4])
        quaternion = quaternion/np.linalg.norm(quaternion)
        # Publish pose
        pose = Pose()
        pose.position.x = position[0]
        pose.position.y = position[1]
        pose.position.z = position[2]
        pose.orientation.w = quaternion[3]
        pose.orientation.x = quaternion[0]
        pose.orientation.y = quaternion[1]
        pose.orientation.z = quaternion[2]
        self._pose_publisher.publish(pose)
        # Publish tf
        self._tf_publisher.sendTransform(position,
                                         quaternion,
                                         rospy.Time.now(),
                                         "box_tf",
                                         "panda_link0")
        self.publish_annoted_image(self.curr_image, self._localizer._points)

    def publish_annoted_image(self, image, points):
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.8
        font_color = (0, 0, 255)
        thickness = 1
        for key, center in points.items():

            cv2.circle(image, center, 10, (0, 0, 255), 2)
            cv2.circle(image, center, 2, (0, 0, 255), 3)
            cv2.putText(image, key, (center[0]+15, center[1]), font, font_scale, font_color, thickness)

        ros_image = self.bridge.cv2_to_imgmsg(image, "bgr8")
        self.image_publisher.publish(ros_image)


    def run(self):
        self._rate.sleep()
        while not rospy.is_shutdown():
            self.publisher_localization()
            self._rate.sleep()
    

if __name__ == '__main__':
    simple_localizer_node = SimpleLocalizerNode()
    try:
        simple_localizer_node.run()
    except rospy.ROSInterruptException:
        pass
